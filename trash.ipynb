{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import pickle\n",
    "data = pickle.load(open(r'D:\\PHD\\Codes\\AutoML\\GraphNAP_V1.0\\data\\graph_anomaly\\elliptic.dat', 'rb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 73248], num_nodes=46564, x=[46564, 93], y=[46564], train_mask=[46564], val_mask=[46564], test_mask=[46564])\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mask count is: 21353\n",
      "val mask count is : 8541\n",
      "test mask count is : 16670\n",
      "total train+ val+test mask count is  46564\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "train_mask =0\n",
    "val_mask=0\n",
    "test_mask=0\n",
    "for i in range(len(data.y)):\n",
    "    if data.train_mask[i]==torch.tensor(1):\n",
    "        train_mask=train_mask+1\n",
    "    if data.val_mask[i]==torch.tensor(1):\n",
    "        val_mask=val_mask+1\n",
    "    if data.test_mask[i]==torch.tensor(1):\n",
    "        test_mask=test_mask+1\n",
    "print(\"train mask count is:\",train_mask)\n",
    "print(\"val mask count is :\",val_mask)\n",
    "print(\"test mask count is :\",test_mask)\n",
    "print(\"total train+ val+test mask count is \",train_mask+val_mask+test_mask)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "train =0\n",
    "test=0\n",
    "no_train=0\n",
    "for i in range(len(data.y)):\n",
    "    if data.train_mask[i]==torch.tensor(1):\n",
    "        train=train+1\n",
    "    else:\n",
    "        no_train=no_train+1\n",
    "print(\"train count\",train)\n",
    "print(\"train count\",train)\n",
    "print(\"train count\",train+no_train)\n",
    "train =0\n",
    "test=0\n",
    "no_train=0\n",
    "for i in range(len(data.y)):\n",
    "    if data.train_mask[i]==torch.tensor(1):\n",
    "        train=train+1\n",
    "    else:\n",
    "        no_train=no_train+1\n",
    "print(\"train count\",train)\n",
    "print(\"train count\",train)\n",
    "print(\"train count\",train+no_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "dataset=Planetoid(root=r\"D:\\PHD\\Codes\\AutoML\\GraphNAP_V1.0\\data\\Planetoid\", name=\"Cora\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
